{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 전처리 - 이미지 데이터 LMDB로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transform import Resize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, regularizers\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, BatchNormalization, Activation, Lambda, add\n",
    "from tensorflow.keras.losses import MeanSquaredError, Reduction\n",
    "from tensorflow.optimizers import Adam\n",
    "\n",
    "class ResNet50(): \n",
    "    _L2_WEIGHT_DECAY = 1e-4\n",
    "\n",
    "    @staticmethod\n",
    "    def _gen_l2_regularizer(use_l2_regularizer=True): \n",
    "        return regularizers.l2(ResNet50._L2_WEIGHT_DECAY) if use_l2_regularizer else None\n",
    "    \n",
    "    @staticmethod\n",
    "    def _identity_block(input, filters, use_l2_regularizer): \n",
    "        filter1, filter2, filter3 = filters\n",
    "\n",
    "        x = Conv2D(filters=filter1, kernel_size=1, strides=1, padding='same', activation=None, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(use_l2_regularizer), data_format='channels_last')(input)\n",
    "        x = BatchNormalization(axis=0)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(filters=filter2, kernel_size=3, strides=1, padding='same', activation=None, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(use_l2_regularizer), data_format='channels_last')(x)\n",
    "        x = BatchNormalization(axis=0)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(filters=filter3, kernel_size=1, strides=1, padding='same', activation=None, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(use_l2_regularizer), data_format='channels_last')(x)\n",
    "        x = BatchNormalization(axis=0)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = add([x, input])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def _conv_block(input, filters, stride, use_l2_regularizer): \n",
    "        filter1, filter2, filter3 = filters\n",
    "\n",
    "        x = Conv2D(filters=filter1, kernel_size=1, strides=1, padding='same', activaiton=None, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(use_l2_regularizer), data_format='channels_last')(input)\n",
    "        x = BatchNormalization(axis=0)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(filters=filter2, kernel_size=3, strides=stride, padding='same', activaiton=None, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(use_l2_regularizer), data_format='channels_last')(x)\n",
    "        x = BatchNormalization(axis=0)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(filters=filter3, kernel_size=1, strides=1, padding='same', activaiton=None, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(use_l2_regularizer), data_format='channels_last')(x)\n",
    "        x = BatchNormalization(axis=0)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        shortcut = Conv2D(filters=filter3, kernel_size=1, strides=stride, padding='same', activation=None, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(use_l2_regularizer), data_format='channels_last')(input)\n",
    "        shortcut = BatchNormalization(axis=0)(shortcut)\n",
    "\n",
    "        x = add([x, shortcut])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __init__(self, global_batch_size, img_size, number_regression_targets, learning_rate=3e-4, use_l2_regularizer=True):\n",
    "        '''\n",
    "        img_size needs to be (H, W, C) format\n",
    "        '''\n",
    "\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.number_regression_targets = number_regression_targets\n",
    "        self.learning_rate = learning_rate\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.use_l2_regularizer = use_l2_regularizer\n",
    "\n",
    "        self.inputs = Input(shape=img_size)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "        self.loss_fn = MeanSquaredError(reduction=Reduction.NONE)\n",
    "\n",
    "        self.optimizer = Adam(learning_rate=self.learning_rate)\n",
    "\n",
    "    def _build_model(self): \n",
    "        x = Conv2D(filters=64, kernel_size=7, strides=2, padding='same', activation=None, use_bias=False, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(self.use_l2_regularizer), data_format='channels_last')(self.inputs)\n",
    "        x = BatchNormalization(axis=0)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "        x = ResNet50._conv_block(x, [64, 64, 256], stride=1, use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [64, 64, 256], use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [64, 64, 256], use_l2_regularizer=self.use_l2_regularizer)\n",
    "\n",
    "        x = ResNet50._conv_block(x, [128, 128, 512], stride=2, use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [128, 128, 512], use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [128, 128, 512], use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [128, 128, 512], use_l2_regularizer=self.use_l2_regularizer)\n",
    "\n",
    "        x = ResNet50._conv_block(x, [256, 256, 1024], stride=2, use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [256, 256, 1024], use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [256, 256, 1024], use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [256, 256, 1024], use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [256, 256, 1024], use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [256, 256, 1024], use_l2_regularizer=self.use_l2_regularizer)\n",
    "\n",
    "        x = ResNet50._conv_block(x, [512, 512, 2048], stride=2, use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [512, 512, 2048], use_l2_regularizer=self.use_l2_regularizer)\n",
    "        x = ResNet50._identity_block(x, [512, 512, 2048], use_l2_regularizer=self.use_l2_regularizer)\n",
    "\n",
    "        rm_axes = [1, 2]\n",
    "        x = Lambda(lambda x: tf.reduce_mean(x, rm_axes))(x)\n",
    "\n",
    "        logits = Dense(self.number_regression_targets, kernel_initializer='he_normal', kernel_regularizer=ResNet50._gen_l2_regularizer(self.use_l2_regularizer), bias_regularizer=ResNet50._gen_l2_regularizer(self.use_l2_regularizer), activation=None, name='logits')(x)\n",
    "\n",
    "        resnet50 = Model(self.inputs, logits, name='resnet50')\n",
    "\n",
    "        return resnet50\n",
    "\n",
    "    def get_keras_model(self): \n",
    "        return self.model\n",
    "    \n",
    "    def get_optimizer(self): \n",
    "        return self.optimizer\n",
    "    \n",
    "    def set_learning_rate(self, learning_rate): \n",
    "        self.optimizer.learning_rate = learning_rate\n",
    "\n",
    "    def get_learning_rate(self): \n",
    "        return self.optimizer.learning_rate\n",
    "    \n",
    "    def train_step(self, inputs): \n",
    "        images, labels, loss_metric = inputs\n",
    "\n",
    "        with tf.GradientTape() as tape: \n",
    "            logits = self.model(images, training=True)\n",
    "\n",
    "            loss_value = self.loss_fn(labels, logits)\n",
    "            loss_value = tf.reduce_sum(loss_value)\n",
    "\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "\n",
    "        loss_metric.update_state(loss_value)\n",
    "\n",
    "        return loss_value\n",
    "    \n",
    "    def test_step(self, inputs): \n",
    "        images, labels, loss_metric = inputs\n",
    "        logits = self.model(images, training=False)\n",
    "\n",
    "        loss_value = self.loss_fn(labels, logits)\n",
    "        \n",
    "        loss_value = tf.reduce_sum(loss_value, axis=0) / self.global_batch_size\n",
    "\n",
    "        loss_metric.update_state(loss_value)\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    # Functions for Multi-GPU environment\n",
    "    @tf.function\n",
    "    def dist_train_step(self, dist_strategy, inputs): \n",
    "        per_gpu_loss = dist_strategy.experimental_run_v2(self.train_step, args=(inputs,))\n",
    "        loss_value = dist_strategy.reduce(tf.distribute.ReduceOp.SUM, per_gpu_loss, axis=None)\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    @tf.function\n",
    "    def dist_test_step(self, dist_strategy, inputs): \n",
    "        per_gpu_loss = dist_strategy.experimental_run_v2(self.test_step, args=(inputs,))\n",
    "        loss_value = dist_strategy.reduce(tf.distribute.ReduceOp.SUM, per_gpu_loss, axis=None)\n",
    "\n",
    "        return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "global_batch_size=64\n",
    "image_size=(250, 250)\n",
    "number_outputs=2\n",
    "train_epoch_size=20\n",
    "test_epoch_size=20\n",
    "train_log_dir = './train_log/'\n",
    "test_log_dir = './test_log/'\n",
    "\n",
    "if not os.path.exists(train_log_dir): os.makedirs(train_log_dir)\n",
    "if not os.path.exists(test_log_dir): os.makedirs(test_log_dir)\n",
    "\n",
    "resnet = ResNet50(global_batch_size, image_size, number_outputs)\n",
    "checkpoint = tf.train.Checkpoint(optimizer=resnet.get_optimizer(), model=resnet.get_keras_model())\n",
    "\n",
    "test_loss = []\n",
    "\n",
    "train_loss_metric = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "test_loss_metric = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "epoch = 0\n",
    "print('Running ResNet50')\n",
    "\n",
    "while True: \n",
    "    print(f'---- Epoch: {epoch} ----')\n",
    "\n",
    "    if epoch == 0: \n",
    "        curr_train_epoch_size = min(1000, train_epoch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
